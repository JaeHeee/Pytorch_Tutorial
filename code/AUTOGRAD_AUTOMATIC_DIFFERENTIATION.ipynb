{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AUTOGRAD: AUTOMATIC DIFFERENTIATION.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtvxC36KUVxRFaOFd/7Y0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeHeee/Pytorch_Tutorial/blob/main/code/AUTOGRAD_AUTOMATIC_DIFFERENTIATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQHLCAaeFR7O"
      },
      "source": [
        "## AUTOGRAD: 자동 미분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2M-qi1oFw1C"
      },
      "source": [
        "PyTorch의 모든 신경망의 중심에는 `autograd` 패키지가 존재.  \n",
        "`autograd` 패키지는 Tensor의 모든 연산에 대해 자동 미분을 제공. 이는 define-by-run 프레임워크로, 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻이며, 역전파는 학습 과정의 매 단계마다 달라진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmRM_U0zF1Zt"
      },
      "source": [
        "### Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHCpH21NHYH6"
      },
      "source": [
        "패키지의 중심에는 `torch.Tensor` 클래스가 존재. 만약 `.requires_grad` 속성을 True로 설정하면, 그 tensor에서 이뤄진 모든 연산들을 추적하기 시작. 계산이 완료된 후, `.backward()`를 호출하여 모든 gradient를 자동을 계산가능. 이 Tensor의 변화도는 `.grad` 속성에 누적됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpcCAJw6HYKz"
      },
      "source": [
        "Tensor가 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산 기록으로부터 분리하여 이후 연산들이 추적되는 것을 방지 가능"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuDmN0GIIMrG"
      },
      "source": [
        "기록을 추적하는 것(과 메모리를 사용하는 것)을 방지하기 위해, 코드 블럭을 `with torch.no_grad():` 로 감쌀 수 있다. 이는 특히 gradient는 필요없지만, `requires_grad=True` 가 설정되어 학습 가능한 매개변수를 갖는 모델을 evaluate할 때 유용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_QNZmCtIMtt"
      },
      "source": [
        "Autograd 구현에서 매우 중요한 또 다른 클래스는 `Function` 클래스 Tensor 와 Function 은 서로 연결되어 있으며, 모든 연산 과정을 encode하여 acyclic graph를 생성. 각 tensor `.grad_fn` 속성을 갖고 있는데, 이는 Tensor 를 생성한 Function 을 참조 (단, 사용자가 만든 Tensor는 예외로, 이 때 `grad_fn`은 `None`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weWE27WwIMwH"
      },
      "source": [
        "derivatives를 계산하기 위해서는 Tensor의 `.backward()` 를 호출. 만약 Tensor 가 scalar인 경우(예. 하나의 요소 값만 갖는 등)에는 `backward` 에 인자를 정해줄 필요가 없지만 여러 개의 요소를 갖고 있을 때는 tensor의 모양을 `gradient` 의 인자로 지정할 필요가 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rT6Cyy0HXfW"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9SpOlhwKSu3"
      },
      "source": [
        "tensor를 생성하고 `requires_grad=True` 를 설정하여 연산을 기록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7bTEgrgHXiG",
        "outputId": "68dba7ae-12cb-4323-a8a9-7311ab239fd6"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMq6kkRzKfLh"
      },
      "source": [
        "tensor에 연산을 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgX9oPHXF0vg",
        "outputId": "b55afc9e-8551-4968-9499-e2efaa027674"
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eUu0Rd7KlUO"
      },
      "source": [
        "y는 연산의 결과로 생성된 것이므로 `grad_fn`을 가진다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXN5-4idF0Pi",
        "outputId": "223807cd-315b-4c23-b35f-dc002d522929"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7fb664269860>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCMYQf7MKzH2"
      },
      "source": [
        "y에 다른 연산을 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCJVGVGAFCYB",
        "outputId": "20f3f65f-886a-4ef9-e682-da60cec09b8e"
      },
      "source": [
        "z = y*y*3 # z = 3(x+2)^2\n",
        "out = z.mean()\n",
        "print(z, out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQKuRFkBLCFE"
      },
      "source": [
        "`.requires_grad(...)`는 기존 Tensor의 `requires_grad` 값을 in-place 하여 변경. 입력값이 지정되지 않으면 기본값은 False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKO5xaL3K4F1",
        "outputId": "b2b45e87-7c62-4218-8022-0bc3233a0f69"
      },
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a*3)/(a-1))\n",
        "print(a.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdx2QSIML3zr",
        "outputId": "288063d1-ed5e-4de5-977e-29afc6842884"
      },
      "source": [
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lyqtafNL5OA",
        "outputId": "13bfa055-31c5-4f77-ed50-3e06b59a0fce"
      },
      "source": [
        "b = (a*a).sum()\n",
        "print(b.grad_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SumBackward0 object at 0x7fb664af2080>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9WIJjdiL9lz"
      },
      "source": [
        "### Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrILV3QAMAlx"
      },
      "source": [
        "out 은 하나의 스칼라 값만 갖고 있기 때문에, `out.backward()` 는 out.backward(torch.tensor(1.)) 과 동일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTLMRXJzL6Dy",
        "outputId": "b0aaa1cd-9a4f-4f4d-fa43-8c67351b0caf"
      },
      "source": [
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27., grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuoD70MYMOkk"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZD3yXTbMZns"
      },
      "source": [
        "gradients d(out)/dx 를 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIFDc1ohMi2G",
        "outputId": "251dd6f7-07e8-4d1d-bf17-18ff67acc342"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO5mOIaJMUBj",
        "outputId": "80076f6d-ec1c-4021-a336-4f349c9ffb27"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhmlVgIYOMUA"
      },
      "source": [
        "`out`을 Tensor \"o\"라고 하면, 다음과 같이 계산가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBu_jfhAM0DZ"
      },
      "source": [
        "$o = \\frac{1}{4}\\Sigma_iz_i$ 이고, $z_i = 3(x_i+2)^2$ 이므로 $z_i|_{x_i=1}=27$. 따라서, $\\frac{\\partial o}{\\partial x_i}=\\frac{3}{2}(x_i+2)$이므로 $\\frac{\\partial o}{\\partial x_i}|_{x_i=1}=\\frac{9}{2}=4.5$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX0t-Bxxg4xm"
      },
      "source": [
        "vector 함수 $\\vec{y}=f(\\vec{x})$ 에서 $\\vec{x}$에 대한 $\\vec{y}$의 gradient는 Jacobian Matrix 이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBAlH0pfpIqC"
      },
      "source": [
        "$\\begin{pmatrix} \\frac{\\partial y_1}{\\partial x_1}\\ ... \\ \\frac{\\partial y_1}{\\partial x_n}\\\\... \\\\ \\frac{\\partial y_m}{\\partial x_1}\\ ... \\ \\frac{\\partial y_m}{\\partial x_n} \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kCsajUYpItG"
      },
      "source": [
        "일반적으로, `torch.autograd` 는 vector-Jacobian product를 계산하는 엔진. 즉, vector $v=(v_1\\ v_2\\ ... v_m)^T$ 에 대해 $v^T \\cdot J$을 연산. 만약 v가 scala 함수 $l=g(\\vec{y})$의 gradient인 경우 $v=(\\frac{\\partial l}{\\partial y_1}\\ ... \\frac{\\partial l}{\\partial y_m})^T$ 이며, chain rule에 따라 vector-Jacobian product는 $\\vec{x}$에 대한 l의 gradient가 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkWrkK6SpIv1"
      },
      "source": [
        "$J^T\\cdot v=\\begin{pmatrix} \\frac{\\partial y_1}{\\partial x_1}\\ ... \\ \\frac{\\partial y_m}{\\partial x_1}\\\\... \\\\ \\frac{\\partial y_1}{\\partial x_n}\\ ... \\ \\frac{\\partial y_m}{\\partial x_n} \\end{pmatrix}\\begin{pmatrix} \\frac{\\partial l}{\\partial y_1}\\\\ .\\\\.\\\\\\frac{\\partial l}{\\partial y_m} \\end{pmatrix}=\\begin{pmatrix} \\frac{\\partial l}{\\partial x_1}\\\\ .\\\\.\\\\\\frac{\\partial l}{\\partial x_n} \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS2Kgrpns9fF"
      },
      "source": [
        "여기서 $v^T \\cdot J$ 은 $J^T\\cdot v$를 취했을 때의 열 vector로 취급할 수 있는 행 vector를 가진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82kVFD_AtTX_"
      },
      "source": [
        "vector-Jacobian product의 이러한 특성은 scala가 아닌 출력을 갖는 모델에 외부 변화도를 제공(feed)하는 것을 매우 편리하게 해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57siCNjJP7Pm"
      },
      "source": [
        "vector-Jacobian product 예시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybG3m7iNMX3C",
        "outputId": "8daa0fc7-9a1a-4b6c-87a7-c24b00051e70"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x*2\n",
        "while y.data.norm() < 1000: # norm -> l2 norm\n",
        "    y = y * 2\n",
        "\n",
        "print(y)ㅁ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 429.5515,  194.7347, 1144.1230], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BTNbJN1Q4jI"
      },
      "source": [
        "이 경우 y는 더 이상 scalar 값이 아님. `torch.autograd`는 전체 Jacobian을 직접 계산할수는 없지만, vector-Jacobian product는 간단히 `backward`에 해당 vector를 인자로 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYK8I9okQNSz",
        "outputId": "6f4607bb-12d1-428b-edaa-b9cdc365fe64"
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqXq9sq0eo4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5714db-ed7d-4c45-a6a0-69550ffe9c89"
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x**2).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x**2).requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eSciCYRt224"
      },
      "source": [
        "또는 `.detach()`를 호출하여 content는 같지만 `require_grad`가 다른 새로운 Tensor를 가져온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP4HkiMAtzxd",
        "outputId": "f3fad400-01d2-450f-f508-6b50e43d8d6c"
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6jwfeivufqd"
      },
      "source": [
        "[autograd.Function 관련문서](https://pytorch.org/docs/stable/autograd.html#function)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ciyvsg7uo_O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}