{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PYTORCH: CUSTOM NN MODULES.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVnZczHs9Jatgo7Y4QW1LD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeHeee/Pytorch_Tutorial/blob/main/code/PYTORCH_CUSTOM_NN_MODULES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoeTq96rNI08"
      },
      "source": [
        "## PYTORCH: CUSTOM NN MODULES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43kGPcZ8NTGa"
      },
      "source": [
        "custom module의 subclass로 모델을 정의. 기존 Module의 간단한 구성보다 더 복잡한 모델을 원한다면, 이 방법으로 모델을 정의하면 된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUmasfvENHIY",
        "outputId": "09dff4e3-ced6-4ec3-af5f-4fd1ee981b3f"
      },
      "source": [
        "import torch\n",
        "\n",
        "class TwoLayerNet(torch.nn.Module):\n",
        "    def __init__(self, D_in, H, D_out):\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(D_in, H)\n",
        "        self.linear2 = torch.nn.Linear(H, D_out)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h_relu = self.linear1(x).clamp(min=0)\n",
        "        y_pred = self.linear2(h_relu)\n",
        "        return y_pred\n",
        "\n",
        "# N : batch size\n",
        "# D_in : input dimension\n",
        "# H : hidden dimension\n",
        "# D_out : output dimension\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# random Tensors to hold input and outputs\n",
        "x = torch.randn(N, D_in)\n",
        "y = torch.randn(N, D_out)\n",
        "\n",
        "# Construct out model by instantiating the class defined above\n",
        "model = TwoLayerNet(D_in, H, D_out)\n",
        "\n",
        "# Construct our loss function and an Optimizer\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
        "for t in range(500):\n",
        "    # Forward pass\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # backward pass 단계 전에 optimizer 객체를 사용하여 update할 변수에 대한 gradient를 0 으로 만든다.\n",
        "    # 이렇게 하는 이유는 기본적으로 .backward()를 호출할 때마다 gradient가 버퍼(buffer)에 (덮어쓰지 않고) 누적되기 때문\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backward pass : model의 parameter에 대한 loss의 gradient를 계산\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer의 step 함수를 호출하면 Update the weights\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 2.4334020614624023\n",
            "199 0.033883675932884216\n",
            "299 0.00109790766146034\n",
            "399 6.00083039898891e-05\n",
            "499 4.240929683874128e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuG5eOT9PV-P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}